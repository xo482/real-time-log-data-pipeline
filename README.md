# Real-Time Log Data Pipeline

<br></br>

## í”„ë¡œì íŠ¸ ì†Œê°œ

ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‚¬ìš©ìë“¤ì˜ í–‰ë™ ë°ì´í„°ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ìˆ˜ì§‘í•˜ê³ , Kafka ê¸°ë°˜ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ê³¼ì •ì„ ê±°ì³ ë°ì´í„°ë¥¼ ì¶”ì¶œ, ë³€í™˜, ì ì¬í•˜ì—¬, ê·¸ ê²°ê³¼ë¥¼ ì‹œê°í™”í•˜ëŠ” ì—”ë“œ-íˆ¬-ì—”ë“œ ë¡œê·¸ íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

ë‹¨ìˆœí•œ ë¡œê·¸ ìˆ˜ì§‘ì„ ë„˜ì–´, ì‚¬ìš©ì í–‰ë™ì˜ íë¦„ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ íŒŒì•…í•˜ê³ , ì‚¬ìš©ìê°€ ì •ì˜í•œ ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ì˜ ì‹¤ì‹œê°„ í•„í„°ë§ ë° í¬ë§· ë³€í™˜ì„ ìˆ˜í–‰í•œ í›„ ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ì‚¬ê²°ì •ì— ìœ ì˜ë¯¸í•œ ë°ì´í„°ë¡œ ê°€ê³µí•´ëƒ…ë‹ˆë‹¤. ë˜í•œ Kafka, Spark, Redis ê¸°ë°˜ì˜ ë¹„ë™ê¸° ì•„í‚¤í…ì²˜ë¡œ ì„¤ê³„ë˜ì–´ ëŒ€ê·œëª¨ íŠ¸ë˜í”½ ì²˜ë¦¬ì—ë„ ìœ ì—°í•˜ê²Œ ëŒ€ì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜](https://github.com/xo482/real-time-log-data-pipeline/blob/dev/images/overview.png)

<br></br>

## ì „ì†¡ë˜ëŠ” ìš”ì²­ ì˜ˆì‹œ ë° íŒŒë¼ë¯¸í„°

ì‚¬ìš©ìê°€ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ë‚´ì—ì„œ ì˜ë„í•œ ë™ì‘ì„ í–ˆì„ ê²½ìš° ê³ ê°ì˜ í–‰ë™ ë°ì´í„°ëŠ” ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° í˜•íƒœë¡œ ë°œìƒë˜ë©°, ì ‘ì† ì‹œì , ë¸Œë¼ìš°ì € ì •ë³´, í™”ë©´ í•´ìƒë„, í´ë¦­ ì´ë²¤íŠ¸ ë“± ë‹¤ì–‘í•œ ì‚¬ìš©ì í–‰ë™ ë°ì´í„°ê°€ í¬í•¨ë©ë‹ˆë‹¤. ì´ ìš”ì²­ì€ NGINXë¥¼ í†µí•´ ìˆ˜ì§‘ë˜ì–´ `access.log`ì— ê¸°ë¡ë˜ë©°, ì´í›„ Fluentdê°€ ì´ë¥¼ Kafkaë¡œ ì „ë‹¬í•˜ëŠ” íŒŒì´í”„ë¼ì¸ì˜ ì¶œë°œì ì´ ë©ë‹ˆë‹¤. ì˜ˆì‹œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

```http
http://[NGINX_URL]/{scenario_id}?
e_c=buttonClick
&e_a=Clicked
&e_n=\uace0\uba74\ud560\ub2f9\ud558\uae30
&url=http://[Tracked_Page]/product_detail/product_name
&urlref=http://[Tracked_Page]/
&_idn=0
&cookie=1
&res=1920x1080
&memberId=123456
```

| íŒŒë¼ë¯¸í„°     | ì„¤ëª…                        |
| -------- | ------------------------- |
| e\_c     | ì´ë²¤íŠ¸ ì¹´í…Œê³ ë¦¬ (ì˜ˆ: buttonClick) |
| e\_a     | ì´ë²¤íŠ¸ ì•¡ì…˜ (ì˜ˆ: Clicked)       |
| e\_n     | ì´ë²¤íŠ¸ ì´ë¦„ (ì˜ˆ: êµ¬ë§¤)            |
| url      | í˜„ì¬ í˜ì´ì§€ URL                |
| urlref   | ì´ì „ í˜ì´ì§€ URL (Referrer)     |
| \_idn    | ì‹ ê·œ ë°©ë¬¸ ì—¬ë¶€ (1ì´ë©´ ì‹ ê·œ)         |
| cookie   | ì¿ í‚¤ ì‚¬ìš© ì—¬ë¶€                  |
| res      | í™”ë©´ í•´ìƒë„ (ì˜ˆ: 1920x1080)     |
| memberId | ì‚¬ìš©ì ID                    |

<br></br>
## ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ ë™ì  ì²˜ë¦¬ êµ¬ì¡°

ì‚¬ìš©ìëŠ” ì§ì ‘ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìƒì„±í•˜ì—¬ ë‹¤ìŒê³¼ ê°™ì€ ì„¤ì •ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

* ì €ì¥í•˜ê³ ì í•˜ëŠ” íŒŒë¼ë¯¸í„° (e.g. e_c, e_a, url ë“±)
* í•„í„° ì¡°ê±´ (ì˜ˆ: age > 20, gender == MALE, h >= 9 ë“±)
* ë…¼ë¦¬ ì—°ì‚° ë°©ì‹ (AND, OR)

ì´ ì‹œë‚˜ë¦¬ì˜¤ëŠ” DBì— ì €ì¥ë˜ë©°, ì´í›„ Kafka Consumerê°€ í•´ë‹¹ ì„¤ì •ì„ ê¸°ì¤€ìœ¼ë¡œ í¬ë§· ë³€í™˜ ë° í•„í„°ë§ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ìˆ˜í–‰í•©ë‹ˆë‹¤.
<br></br>
#### ì‹œë‚˜ë¦¬ì˜¤ ì •ì˜ ì˜ˆì‹œ (JSON)

```json
{
  "scenario_id": 5,
  "title": "9ì‹œ ì´í›„ êµ¬ë§¤ ë²„íŠ¼ì„ í´ë¦­í•œ ì„±ì¸ ë‚¨ì„± ì‚¬ìš©ì í•„í„°ë§",
  "manager": "admin_user",
  "log_format": {
    "e_c": 0,
    "e_a": 0,
    "memberId": 1,
    "h": 1,
    "res": 0,
    ...
  },
  "filters": [
    { "left": "age", "operator": ">", "right": "20" },
    { "left": "gender", "operator": "==", "right": "MALE" },
    { "left": "h", "operator": ">=", "right": "9" }
  ],
  "logical_operator": "AND"
}
```

<br></br>

## ì‹œìŠ¤í…œ êµ¬ì„± ìš”ì†Œ ë° ë°ì´í„° íë¦„

### Nginx â†’ Fluentd â†’ Kafka ë¡œê·¸ ì „ì†¡

FluentdëŠ” ì•„ë˜ì™€ ê°™ì€ ì„¤ì •ìœ¼ë¡œ Nginxì˜ access.log íŒŒì¼ì„ tailí•˜ë©° Kafkaë¡œ ì „ì†¡í•©ë‹ˆë‹¤.

```xml
<source>
  @type tail
  path /var/log/nginx/access.log
  pos_file /fluentd/status/nginx-access.pos
  tag nginx.access
  @label @LOGGING
  <parse>
    @type nginx
  </parse>
</source>
```
<br></br>
### Kafka â†’ Spring ì„œë¹„ìŠ¤: ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ í¬ë§· ì²˜ë¦¬ ë° í•„í„°ë§

* Kafkaì— ì €ì¥ëœ ë¡œê·¸ëŠ” `ScenarioProcessingService`ê°€ ìˆ˜ì‹ í•©ë‹ˆë‹¤.
* ë¡œê·¸ ë‚´ë¶€ì˜ `scenario_id`ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
* ì‹œë‚˜ë¦¬ì˜¤ì—ëŠ” ì¶œë ¥ í•„ë“œì™€ í•„í„° ì¡°ê±´ì´ í¬í•¨ë˜ë©°, ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ success ì—¬ë¶€ë¥¼ íŒë³„í•©ë‹ˆë‹¤.
* í¬ë§· í•„ë“œê°€ 0ì´ë©´ í•´ë‹¹ í•­ëª©ì€ ì œê±°ë©ë‹ˆë‹¤.
* í•„í„° ì¡°ê±´ì„ ëª¨ë‘ ë§Œì¡±í•˜ë©´ success: 1, ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ success: 0 ìœ¼ë¡œ ì„¤ì •ë©ë‹ˆë‹¤.
* ìµœì¢… JSONì— `success`, `scenario_id`, `date` í•„ë“œ í¬í•¨ í›„ ë‹¤ìŒ í† í”½ìœ¼ë¡œ ì „ì†¡ë©ë‹ˆë‹¤.
  
<br></br>
### Spark Streaming ì²˜ë¦¬

* HDFS ì €ì¥

```python
# -------------------- HDFS ì €ì¥ --------------------
query_hadoop = flattened_df.writeStream \
    .format("parquet") \
    .option("path", f"hdfs://[HDFS_IP]:9000/kafka_sink_output") \
    .option("checkpointLocation", f"hdfs://[HDFS_IP]:9000/spark-checkpoint") \
    .outputMode("append") \
    .start()
```

<br></br>
* Kafkaë¡œë¶€í„° ì‹¤ì‹œê°„ ë¡œê·¸ ìˆ˜ì‹ 
* success ì—¬ë¶€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„±ê³µë¥  í†µê³„ ì§‘ê³„
* Redis ì €ì¥ ë³‘ë ¬ ìˆ˜í–‰

```python
# -------------------- Redis ì €ì¥ í•¨ìˆ˜ --------------------
def write_to_redis(batch_df, epoch_id):
    scenario_stats = batch_df.groupBy("scenario_id").agg(
        spark_sum("success").alias("success_count"),
        count("*").alias("total_count"))
    now_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    r = redis.StrictRedis(host="[REDIS_IP]", port=6379, db=0)

    for row in scenario_stats.collect():
        sid = row["scenario_id"]
        total = row["total_count"]
        success = row["success_count"] or 0
        ratio = round(success / total, 4) if total else 0

        value = json.dumps({
            "success_ratio": ratio,
            "total_count": total,
            "success_count": success,
            "updated_at": now_str
        })

        r.set(f"scenario:{sid}:success_ratio", value)


# -------------------- Redis ì €ì¥ ì¿¼ë¦¬ --------------------
query_redis = flattened_df.select("scenario_id", "success").writeStream \
    .outputMode("append") \
    .trigger(processingTime="5 seconds") \
    .foreachBatch(write_to_redis) \
    .option("checkpointLocation", f"hdfs://{HDFS_IP}:9000/checkpoint_success_ratio_pt") \
    .start()

)
```
<br></br>
* Redis ì €ì¥ ì˜ˆì‹œ

```json
{
  "success_ratio": 0.85,
  "total_count": 100,
  "success_count": 85,
  "updated_at": "2025-06-18 12:50:10"
}
```

<br></br>
## ì‹¤ì‹œê°„ ì‹œê°í™” ì‹œìŠ¤í…œ

* ğŸ”§ ê´€ë¦¬ì í˜ì´ì§€: Redisì— ì €ì¥ëœ scenario ë³„ success í†µê³„ë¥¼ 5ì´ˆ ë‹¨ìœ„ë¡œ UIì—ì„œ EChartsë¡œ ì‹œê°í™”í•˜ì—¬ ê´€ë¦¬ìê°€ ì„¤ì •í•œ ì‹œë‚˜ë¦¬ì˜¤ì— ëŒ€í•œ ë°ì´í„°ê°€ ì–¼ë§ˆë‚˜ ìˆ˜ì§‘ë˜ê³  ìˆëŠ”ì§€ì™€ ì •ìƒì ìœ¼ë¡œ ìˆ˜ì§‘ë˜ê³  ìˆëŠ”ì§€ í™•ì¸

  <img src="https://github.com/xo482/real-time-log-data-pipeline/blob/dev/images/graph.png" width="600">

* ğŸ“Š Grafana: Prometheusë¥¼ í™œìš©í•´ Kafka, Spark, Redisì˜ ì„±ëŠ¥ ë° ì§€ì—° ì‹œê°„ ë“± ì‹œìŠ¤í…œ ì „ë°˜ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ê³  ì¹´í”„ì¹´ Lag ê°ì‹œ ë° TPS ì¸¡ì •

  <img src="https://github.com/xo482/real-time-log-data-pipeline/blob/dev/images/monitoring.png" width="600">

<br></br>
##ê¸°ìˆ  ìŠ¤íƒ

| ë²”ì£¼             | ì‚¬ìš© ê¸°ìˆ  ë° ë„êµ¬                                             | ì„¤ëª…                                     |
| -------------- | ------------------------------------------------------ | -------------------------------------- |
| **ë°ì´í„° ìˆ˜ì§‘**     | **NGINX(access.log)**, **Matomo Tag Manager**, | ì›¹ ì‚¬ìš©ì í–‰ë™ ë°ì´í„°ë¥¼ ì¶”ì í•˜ì—¬ ë¡œê·¸ë¡œ ì €ì¥              |
| **ë¡œê·¸ ìˆ˜ì§‘/ì „ì†¡**   | **Fluentd**                                            | NGINX ë¡œê·¸ë¥¼ ìˆ˜ì§‘í•˜ì—¬ Kafkaë¡œ ì „ì†¡ (tail ê¸°ë°˜)     |
| **ë©”ì‹œì§€ ë¸Œë¡œì»¤**    | **Apache Kafka** (3-broker, KRaft mode)                | ë¡œê·¸ ë©”ì‹œì§€ë¥¼ ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì „ë‹¬               |
| **ì‹¤ì‹œê°„ ì²˜ë¦¬ (1)** | **Spring Kafka (Java)**                                | Kafka ë©”ì‹œì§€ë¥¼ ì†Œë¹„í•˜ì—¬ ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ í•„í„°ë§ ë° í¬ë§· ë³€í™˜ ìˆ˜í–‰ |
| **ì‹¤ì‹œê°„ ì²˜ë¦¬ (2)** | **Apache Spark Structured Streaming (PySpark)**        | Kafka ë©”ì‹œì§€ë¥¼ ë³‘ë ¬ ì²˜ë¦¬í•˜ì—¬ ì‹¤ì‹œê°„ í†µê³„ ì§‘ê³„ ë° ì €ì¥      |
| **ë°ì´í„° ì €ì¥ì†Œ**    | **Redis**                                              | ì‹œë‚˜ë¦¬ì˜¤ ë° ì‚¬ìš©ì ì •ë³´ ìºì‹±, ì‹¤ì‹œê°„ ì„±ê³µë¥  ì €ì¥           |
|                | **HDFS**                                               | ì›ë³¸ ë¡œê·¸ ë°ì´í„° ì˜êµ¬ ì €ì¥ (Parquet í¬ë§·)           |
|                | **MariaDB**                                            | ì‚¬ìš©ì(Member), ì‹œë‚˜ë¦¬ì˜¤(Scenario) ë“± ê¸°ì¤€ ì •ë³´ ì €ì¥ |
| **ì‹œê°í™”**        | **ECharts**                                            | Redis ê¸°ë°˜ ì‹¤ì‹œê°„ ì„±ê³µë¥  ì‹œê°í™” (ì›¹ ê¸°ë°˜)            |
|                | **Grafana + Prometheus**                               | Kafka/Spark/ì‹œìŠ¤í…œ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ìš© ëŒ€ì‹œë³´ë“œ êµ¬ì¶•       |
| **ì¸í”„ë¼**        | **AWS EC2**, **Docker Compose**                        | í´ë¼ìš°ë“œ ê¸°ë°˜ ë¶„ì‚° ì²˜ë¦¬ í™˜ê²½ êµ¬ì¶•    |

